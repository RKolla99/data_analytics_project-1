{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-177808a2c68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from math import log\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('./dataset/train_values.csv')\n",
    "train_labels = pd.read_csv('./dataset/train_labels.csv')\n",
    "test_values = pd.read_csv('./dataset/test_values.csv')\n",
    "submission = pd.read_csv('./dataset/submission_format.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing, NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.isnull().values.any()\n",
    "train_labels.isnull().values.any()\n",
    "\n",
    "#The dataset contains no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=train_values[\"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the boxplot for the age of the buildings shows outliers, according to other sources, the buildings in Nepal actually date back to several thousands of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({ 'Train': train_values[\"area_percentage\"], 'Test' : test_values[\"area_percentage\"]})\n",
    "ax = sns.boxplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({ 'Train': train_values[\"height_percentage\"], 'Test' : test_values[\"height_percentage\"]})\n",
    "ax = sns.boxplot(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot eliminate all the outliers in the train data as the test data also contains outliers similar to the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categorical variables into Numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns with categorical data\n",
    "num_cols = train_values._get_numeric_data().columns\n",
    "categories = list(set(train_values.columns) - set(num_cols))\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categories:\n",
    "    print(i, set(train_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot Encodings\n",
    "train_values_new = pd.get_dummies(train_values)\n",
    "test_values_new = pd.get_dummies(test_values)\n",
    "\n",
    "print('Training dataset :',train_values_new.shape)\n",
    "print()\n",
    "print('Test dataset :',test_values_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factors Method\n",
    "\n",
    "#Preparing Training Data\n",
    "df = train_values\n",
    "for col_name in categories:\n",
    "        df[col_name]= df[col_name].astype('category')\n",
    "        df[col_name] = df[col_name].cat.codes\n",
    "print(\"Train Data Shape: \", df.shape)\n",
    "\n",
    "#Preparing Test Data\n",
    "df_test = test_values\n",
    "for col_name in categories:\n",
    "        df_test[col_name]= df_test[col_name].astype('category')\n",
    "        df_test[col_name] = df_test[col_name].cat.codes\n",
    "print(\"Test Data Shape: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Summary Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On plotting a bar plot for each damage grade, we observe that the data is imbalanced.\n",
    "# Countplot of 'damage_grade' column ( Counts of different damage grades )\n",
    "\n",
    "sns.set(rc={'figure.figsize':(6,7)})\n",
    "sns.countplot(train_labels['damage_grade']).set_title(\"Number of Buildings with Each Damage Grade\")\n",
    "plt.show()\n",
    "damage_grade_count = train_labels['damage_grade'].value_counts()\n",
    "print(damage_grade_count)\n",
    "print()\n",
    "print('It can be clearly seen that most (about %.2f%%) of the buildings have been moderately (damage_grade = 2) damaged by the earthquake' \n",
    "      %(round(damage_grade_count[2]/sum(damage_grade_count)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,11))\n",
    "data_corr = train_values.corr()\n",
    "sns.heatmap(data_corr)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of a few selected columns\n",
    "\n",
    "print('The below plot shows relationship between a few selected columns')\n",
    "df_merged = train_values.merge(train_labels)\n",
    "selected_features = ['age',\n",
    "                 'area_percentage',\n",
    "               'height_percentage',\n",
    "               'foundation_type',\n",
    "               'count_families',\n",
    "               'has_secondary_use',\n",
    "                'damage_grade']\n",
    "\n",
    "df_merged = df_merged[selected_features]\n",
    "\n",
    "sns.pairplot(data = df_merged, hue = \"damage_grade\", diag_kind = \"hist\", kind = \"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 'age' column ( Distribution of age of the buildings )\n",
    "\n",
    "sns.set(rc={'figure.figsize':(16,8)})\n",
    "sns.distplot(df.age, bins = 200, kde = True)\n",
    "plt.title('Distribution of age of the buildings')\n",
    "plt.show()\n",
    "\n",
    "# log transformation applied on age column for values greater than 0\n",
    "# sns.set(rc={'figure.figsize':(16,8)})\n",
    "# sns.distplot(df.age[df.age>0].apply(log), bins = 40, kde = True)\n",
    "# plt.title('Distribution of age of the buildings after log transformation')\n",
    "# plt.show()\n",
    "\n",
    "num_of_zeros = df['age'].to_list().count(0)\n",
    "print('Number of zeros(in age column): ',num_of_zeros)\n",
    "print('26k zeros can imply two things, all those building were built in the past year(pretty unlikely) or that there were some unknown values and they have been filled with 0')\n",
    "print()\n",
    "print('From the above histogram we can infer that most of the buildings that were destroyed during the earthquake were new or recently build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of 'has_secondary_use' column ( Number of buildings having secondary use )\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "sns.countplot(df['has_secondary_use'])\n",
    "plt.title('Number of buildings having secondary use')\n",
    "plt.xlabel('Secondary Use')\n",
    "plt.xticks(np.arange(2), ('No', 'Yes'))\n",
    "plt.show()\n",
    "secondary_use_count = df['has_secondary_use'].value_counts()\n",
    "print(secondary_use_count)\n",
    "print()\n",
    "print('Only a small percentage (%.2f%%) of the buildings had a secondary use' %(round(secondary_use_count[1]/len(df.has_secondary_use)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for 'count_families' column ( frequency of number of families )\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,7)})\n",
    "sns.countplot(df.count_families)\n",
    "plt.title('Frequency of number of families in a building')\n",
    "plt.xlabel('Number of families')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "families_count = df['count_families'].value_counts()\n",
    "print(families_count)\n",
    "print()\n",
    "print('Majority of the buildings (about %.2f%%) had only 1 family living in them' %(round((families_count[1]/len(df.count_families))*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 'area_percentage' column   ( Distribution of area percentage of the buildings )\n",
    "\n",
    "print('area_percentage represents the normalized area of the building footprint')\n",
    "sns.set(rc={'figure.figsize':(16,8)})\n",
    "sns.distplot(df.area_percentage)\n",
    "plt.title('Distribution of area percentage of the buildings')\n",
    "plt.show()\n",
    "print('The above distribution of area percentage shows it is positively(right) skewed')\n",
    "print('So, we can use log transformation to make the distribution more normal')\n",
    "print()\n",
    "sns.distplot(df.area_percentage.apply(log))\n",
    "plt.title('Distribution of area percentage of the buildings after log transformation')\n",
    "plt.xlabel('log (area_percentage)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 'height_percentage' column  ( Distribution of height percentage of the buildings )\n",
    "\n",
    "print('height_percentage represents the normalized height of the building footprint')\n",
    "sns.set(rc={'figure.figsize':(12,7)})\n",
    "sns.distplot(df.height_percentage)\n",
    "plt.title('Distribution of height percentage of the buildings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "#     #df.hist(column=i, bins=10)\n",
    "#     sns.distplot(df[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Models:\n",
    "1. Logistic Regression\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, train_labels['damage_grade'], test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_train, y_pred):\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, range(3), range(3))\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(y_train), index = np.unique(y_train))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    ax = sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size\n",
    "    ax.get_ylim()\n",
    "    ax.set_ylim(3.0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=1, solver='lbfgs', \n",
    "                         multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred_labels = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print(\"Accuracy of Random Forest: \",clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
